 ---
title: "36-402 Final Project"
author: "Darin Chaoui Jett Hays Emily Huang"
date: "4-12-23"
output: pdf_document
---


```{r}
# load data
sharkTank = read.csv("sharkTank.csv", header=TRUE)
```


## Intro

## Predicting Shark Tank Success
We are also interested in predicting the success of shark tank applicants. A better understanding of what factors influence investor decisions can help founders create better pitches. 

```{r, message=FALSE}
# load required packages
library("np")
library("mgcv")
library("ggplot2")
```


```{r}
# create separate df to avoid conflict w/ other sections
sharkTank2 = sharkTank
# code deal as 1/0
sharkTank2$success = as.integer(as.logical(sharkTank2$deal))
# factorize categorical predictors
sharkTank2$category = as.factor(sharkTank2$category)
sharkTank2$multiple_entreprenuers = as.factor(as.logical(sharkTank2$multiple_entreprenuers))
# sharkTank2$episode = as.factor(sharkTank$episode)
# create transformed predictors
sharkTank2$descriptionLen = nchar(sharkTank$description)
sharkTank2$websiteLen = nchar(sharkTank$website)
sharkTank$titleLen = nchar(sharkTank$title)
```

Our response of interest is pitch 'success'. A pitch is considered successful if the founders earned a deal (denoted as 1). The table below indicates that more pitches are successful than unsuccessful. This may reflect selection bias, with show creators more likely to broadcast high quality pitches. Regardless, the difference is small and does not cause concern about class imbalance. 

```{r}
# table 
dealTable = table(sharkTank2$success)
# rename table columns
rownames(dealTable) = c("Failure", "Success")
dealTable
```

We use logistic regression to model the relationship between deal success and predictors. Our first model will include 'product category' and whether or not a company had multiple founders as categorical predictors. In addition we include the following quantitative predictors: description length, title length, website length, valuation, exchange for stake, and amount asked for.

```{r}
# fit full model
sharkModFull = glm(success ~ category + multiple_entreprenuers + descriptionLen + websiteLen + titleLen + valuation + askedfor + exchangeforstake,
data = sharkTank2, family = binomial)
```

The full model achieves an AIC (an estimator of prediction error) of 728. In adition, we notice that only 'askedFor' and 'descriptionLen' were considered 'significant', with coefficient p-values below the standard .o5 significance threshold. 

Next, we run backwards elimination to find a reduced model that minimizes AIC. 

```{r}
sharkModOpt = step(sharkModFull, direction = "backward", trace = 0)
```


```{r}
sharkModTest = anova(sharkModFull, sharkModOpt, test="Chisq")
sharkModTest
sharkModTestStat=sharkModTest$Deviance[2]
```

Our reduced model only includes description length, valuation, and exchange for stake as predictors. The model achieves an AIC of 675 hich is lower than our full model. To determine whether or not, the full modfel is justified, we run a deviance analysis test. Our null hypothesis is that the full model does not have a significant increase in predictive power. After running our test, we obtain a p-value of .3259, which falls outside of .05 significance threshold. 

Since the reduced model is simpler and achieves better predictive performance than the full model, we will proceed with the reduced model. Analyzing the model coefficients, we can see that valuation is associated with almost no difference in the odds of getting a deal. We also notice that every one percent increase in exchange for stake is associated with a multiplication of the odds of deal success by ~.977. This means that requests for higher percentage of the company are associated with a decrease in the odds of getting a deal. The confusion matrix of predictions is shown below. 

```{r}
# compute classification accuracy
n <- nrow(sharkTank2)
# fitted vals
p <- fitted(sharkModOpt)
names(p) <- NULL
# .05 threshold 
sharkPreds <- ifelse(p > 0.5, 1, 0)
# confusion matrix
sharkPredTable = table(sharkTank2$success, sharkPreds)
names(dimnames(sharkPredTable)) <- c("Observed", "Predicted")
# in-sample error rate (i.e. training error rate )
error = sum(sharkTank2$success != sharkPreds) / n
# interpreted coefficients
interpSharkCoef = exp(coef(sharkModOpt))
```

```{r}
# visualize confusion matrix
sharkPredDf = data.frame(sharkPredTable)
ggplot(data =  sharkPredDf, mapping = aes(x = Observed, y = Predicted)) +
  geom_tile(aes(fill = Freq), colour = "white") +
  geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
  scale_fill_gradient(low = "red", high = "green") +
  theme_bw() + theme(legend.position = "none")+labs(title="Reduced Model Confusion Matrix", caption = "The confusion matrix for our reduced logistic regression model. True positives and true negatives are shown in shades of green.")
```

The confusion matrix indicates our model produces more false positives than false negatives at a .5 classification threshold. Overall, the in sample classification accuracy of our reduced model is ~.6. 




## Conclusion 
 